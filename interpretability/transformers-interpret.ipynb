{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When installing using pip install transformers_interpret I got an import error.\n",
    "Installing from the repository worked correctly\n",
    "git clone https://github.com/cdpierse/transformers-interpret/tree/master/transformers_interpret/explainers\n",
    "pip install . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "from transformers_interpret import TokenClassificationExplainer\n",
    "from utils_ner import NerDataset, Split, get_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to run the example from the documentation\n",
    "#model = AutoModelForTokenClassification.from_pretrained('dslim/bert-base-NER')\n",
    "#tokenizer = AutoTokenizer.from_pretrained('dslim/bert-base-NER')\n",
    "\n",
    "#ner_explainer = TokenClassificationExplainer(\n",
    "#    model,\n",
    "#    tokenizer,\n",
    "#)\n",
    "\n",
    "#sample_text = \"We visited Paris last weekend, where Emmanuel Macron lives.\"\n",
    "\n",
    "#word_attributions = ner_explainer(sample_text, ignored_labels=['O'])\n",
    "\n",
    "#ner_explainer.visualize(\"bert_ner_viz.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove if not needed\n",
    "# sys.path.append(\"..\")\n",
    "DATA_DIR=\"../../datasets/NER/i2b2-2010/merged\"\n",
    "model_name=\"dmis-lab/biobert-base-cased-v1.1\"\n",
    "model_path =\"../output/i2b2-2010\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = os.path.join(DATA_DIR,\"labels.txt\")\n",
    "labels = get_labels(labels_file)\n",
    "label_map: Dict[int, str] = {i: label for i, label in enumerate(labels)}\n",
    "num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "        model_path,\n",
    "        num_labels=num_labels,\n",
    "        id2label=label_map,\n",
    "        label2id={label: i for i, label in enumerate(labels)},\n",
    "        #cache_dir=model_args.cache_dir,\n",
    "    )\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    #cache_dir=model_args.cache_dir,\n",
    "    #use_fast=model_args.use_fast,\n",
    ")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_path,\n",
    "    from_tf=False,\n",
    "    config=config,\n",
    "#    cache_dir=model_args.cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_explainer = TokenClassificationExplainer(\n",
    "    model,\n",
    "    tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"A computerized tomography scan demonstrated a contrast enhancing complex left renal mass. Metastatic work-up was negative.\"\n",
    "\n",
    "word_attributions = ner_explainer(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_explainer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"The patient will get rehabilitation and continue to get care for his fluid.\"\n",
    "\n",
    "word_attributions = ner_explainer(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_explainer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"There has been interval development of moderate amount of high-attenuation fluid within the effusion consistent with hemorrhage.\"\n",
    "word_attributions = ner_explainer(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_explainer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Your atenolol has increased to 50 mg a day.\"\n",
    "word_attributions = ner_explainer(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_explainer.visualize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('biobert_nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bac54cf77d0ab763bf7d73c612772dc11bd10cab788d47696bf8064f827f10e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
